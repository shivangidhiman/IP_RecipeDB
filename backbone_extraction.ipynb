{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "backbone_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uLxLcS0gFDQ"
      },
      "source": [
        "# Data Analysis: RecipeDB\n",
        "## 4.2 Network Analysis - Backbone Extraction\n",
        "---\n",
        "\n",
        "To extract the backbone structure of an undirected weighted network, Disparity Filter - a network reduction algorithm is used.\n",
        "\n",
        "\n",
        "Disparity filter identifies the links that should be preserved in the network. \n",
        "<br>The Null hypothesis used is: normalized weights that correspond to the connections of a certain node of degree k are produced by a random assignment from a uniform distribution.\n",
        "<br>By imposing a significance level $\\alpha$, the links that carry weights that can be considered not compatible with a random distribution can be filtered out with a certain statistical significance.\n",
        "\n",
        "The statistically relevant edges will be those whose weights satisfy the relation:<br>\n",
        "$$\\displaystyle\\alpha_{ij} = 1 - (k - 1) \\int_{0}^{p_{ij}}(1 - x)^{k-2}dx < \\alpha$$\n",
        "where,\n",
        "<br>$k$: number of connections of the node to which the link under consideration is attached.\n",
        "<br>$p_{ij}$: normalised weight.\n",
        "<br>$\\alpha_{ij}$: probability that the node's normalised weight $p_{ij}$ is compatible with the null hypothesis.\n",
        "\n",
        "The multiscale backbone is then obtained by preserving all the links that satisfy the above criterion for at least one of the two nodes at the ends of the link while discounting the rest.\n",
        "\n",
        "<br>\n",
        "\n",
        "<em>Reference</em>: M. A. Serrano et al. (2009) Extracting the Multiscale backbone of complex weighted networks. PNAS, 106:16, pp. 6483-6488.\n",
        "<br>The following code has been taken from: [aekpalakorn/python-backbone-network/blob/master/backbone.py](https://github.com/aekpalakorn/python-backbone-network/blob/master/backbone.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzMn4b7jisFv"
      },
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "from scipy import integrate\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w29DXtwfUCG"
      },
      "source": [
        "'''\n",
        "This module implements the disparity filter to compute a significance score of edge weights in networks\n",
        "'''\n",
        "\n",
        "def disparity_filter(G, weight='weight'):\n",
        "    ''' Compute significance scores (alpha) for weighted edges in G as defined in Serrano et al. 2009\n",
        "        Args\n",
        "            G: Weighted NetworkX graph\n",
        "        Returns\n",
        "            Weighted graph with a significance score (alpha) assigned to each edge\n",
        "        References\n",
        "            M. A. Serrano et al. (2009) Extracting the Multiscale backbone of complex weighted networks. PNAS, 106:16, pp. 6483-6488.\n",
        "    '''\n",
        "    \n",
        "    if nx.is_directed(G): #directed case    \n",
        "        N = nx.DiGraph()\n",
        "        for u in G:\n",
        "            \n",
        "            k_out = G.out_degree(u)\n",
        "            k_in = G.in_degree(u)\n",
        "            \n",
        "            if k_out > 1:\n",
        "                sum_w_out = sum(np.absolute(G[u][v][weight]) for v in G.successors(u))\n",
        "                for v in G.successors(u):\n",
        "                    w = G[u][v][weight]\n",
        "                    p_ij_out = float(np.absolute(w))/sum_w_out\n",
        "                    alpha_ij_out = 1 - (k_out-1) * integrate.quad(lambda x: (1-x)**(k_out-2), 0, p_ij_out)[0]\n",
        "                    N.add_edge(u, v, weight = w, alpha_out=float('%.4f' % alpha_ij_out))\n",
        "                    \n",
        "            elif k_out == 1 and G.in_degree(G.successors(u)[0]) == 1:\n",
        "                #we need to keep the connection as it is the only way to maintain the connectivity of the network\n",
        "                v = G.successors(u)[0]\n",
        "                w = G[u][v][weight]\n",
        "                N.add_edge(u, v, weight = w, alpha_out=0., alpha_in=0.)\n",
        "                #there is no need to do the same for the k_in, since the link is built already from the tail\n",
        "            \n",
        "            if k_in > 1:\n",
        "                sum_w_in = sum(np.absolute(G[v][u][weight]) for v in G.predecessors(u))\n",
        "                for v in G.predecessors(u):\n",
        "                    w = G[v][u][weight]\n",
        "                    p_ij_in = float(np.absolute(w))/sum_w_in\n",
        "                    alpha_ij_in = 1 - (k_in-1) * integrate.quad(lambda x: (1-x)**(k_in-2), 0, p_ij_in)[0]\n",
        "                    N.add_edge(v, u, weight = w, alpha_in=float('%.4f' % alpha_ij_in))\n",
        "        return N\n",
        "    \n",
        "    else: #undirected case\n",
        "        B = nx.Graph()\n",
        "        for u in G:\n",
        "            k = len(G[u])\n",
        "            if k > 1:\n",
        "                sum_w = sum(np.absolute(G[u][v][weight]) for v in G[u])\n",
        "                for v in G[u]:\n",
        "                    w = G[u][v][weight]\n",
        "                    p_ij = float(np.absolute(w))/sum_w\n",
        "                    alpha_ij = 1 - (k-1) * integrate.quad(lambda x: (1-x)**(k-2), 0, p_ij)[0]\n",
        "                    B.add_edge(u, v, weight = w, alpha=float('%.4f' % alpha_ij))\n",
        "        return B\n",
        "\n",
        "def disparity_filter_alpha_cut(G,weight='weight',alpha_t=0.4, cut_mode='or'):\n",
        "    ''' Performs a cut of the graph previously filtered through the disparity_filter function.\n",
        "        \n",
        "        Args\n",
        "        ----\n",
        "        G: Weighted NetworkX graph\n",
        "        \n",
        "        weight: string (default='weight')\n",
        "            Key for edge data used as the edge weight w_ij.\n",
        "            \n",
        "        alpha_t: double (default='0.4')\n",
        "            The threshold for the alpha parameter that is used to select the surviving edges.\n",
        "            It has to be a number between 0 and 1.\n",
        "            \n",
        "        cut_mode: string (default='or')\n",
        "            Possible strings: 'or', 'and'.\n",
        "            It works only for directed graphs. It represents the logic operation to filter out edges\n",
        "            that do not pass the threshold value, combining the alpha_in and alpha_out attributes\n",
        "            resulting from the disparity_filter function.\n",
        "            \n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        B: Weighted NetworkX graph\n",
        "            The resulting graph contains only edges that survived from the filtering with the alpha_t threshold\n",
        "    \n",
        "        References\n",
        "        ---------\n",
        "        .. M. A. Serrano et al. (2009) Extracting the Multiscale backbone of complex weighted networks. PNAS, 106:16, pp. 6483-6488.\n",
        "    '''    \n",
        "    \n",
        "    if nx.is_directed(G):#Directed case:   \n",
        "        B = nx.DiGraph()\n",
        "        for u, v, w in G.edges(data=True):\n",
        "            try:\n",
        "                alpha_in =  w['alpha_in']\n",
        "            except KeyError: #there is no alpha_in, so we assign 1. It will never pass the cut\n",
        "                alpha_in = 1\n",
        "            try:\n",
        "                alpha_out =  w['alpha_out']\n",
        "            except KeyError: #there is no alpha_out, so we assign 1. It will never pass the cut\n",
        "                alpha_out = 1  \n",
        "            \n",
        "            if cut_mode == 'or':\n",
        "                if alpha_in<alpha_t or alpha_out<alpha_t:\n",
        "                    B.add_edge(u,v, weight=w[weight])\n",
        "            elif cut_mode == 'and':\n",
        "                if alpha_in<alpha_t and alpha_out<alpha_t:\n",
        "                    B.add_edge(u,v, weight=w[weight])\n",
        "        return B\n",
        "\n",
        "    else:\n",
        "        B = nx.Graph()#Undirected case:   \n",
        "        for u, v, w in G.edges(data=True):\n",
        "            \n",
        "            try:\n",
        "                alpha = w['alpha']\n",
        "            except KeyError: #there is no alpha, so we assign 1. It will never pass the cut\n",
        "                alpha = 1\n",
        "                \n",
        "            if alpha<alpha_t:\n",
        "                B.add_edge(u,v, weight=w[weight])\n",
        "        return B          "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLfDfEn2ghx8"
      },
      "source": [
        "We will now read the file ingredient_weights.csv that stores the weighted graph of ingredients having common recipes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5Wxk2BbfdiB",
        "outputId": "af523ac6-43da-44d8-9cfe-cde312e88d0f"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    #read the file\n",
        "    G = nx.read_edgelist('output_files/ingredient_weights.csv', delimiter=',' , encoding='latin1',create_using=nx.Graph(),nodetype=str,data=(('weight',int),))\n",
        "    alpha = 0.05\n",
        "    \n",
        "    #use the disparity filter algorithm\n",
        "    G = disparity_filter(G)\n",
        "    G2 = nx.Graph([(u, v, d) for u, v, d in G.edges(data=True) if d['alpha'] < alpha])\n",
        "    print('alpha =', alpha)\n",
        "    print('The extracted backbone structure contains: \\n{0:.2f}% of the original nodes \\n{1:.2f}% of the original edges'.format((G2.number_of_nodes()/G.number_of_nodes())*100, (G2.number_of_edges()/G.number_of_edges())*100))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha = 0.05\n",
            "The extracted backbone structure contains: \n",
            "22.44% of the original nodes \n",
            "5.71% of the original edges\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTo7mrw-grP2"
      },
      "source": [
        "If we take $\\alpha = 0.05$, the extracted backbone structure contains: \n",
        "- 21.52% of the original nodes \n",
        "- 5.74% of the original edges\n",
        "\n",
        "Thus, we can significantly reduce the components in our network while simultaneously preserving the backbone structure."
      ]
    }
  ]
}